{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Idriss-jedid/Automated-Contract-Photo-Verification/blob/master/Computer%20Vision%20/%20Car_Face_Classification_Using_Deep_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8z1fmp1mZl_X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb7368ec-6d6f-49d0-a18a-a09ec56b07dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (1.0.11)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.20.0+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.24.7)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install timm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pYLyKuP4ZOTD"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsf7CB2euSux",
        "outputId": "b569d96d-7739-475f-c0af-7f80e82778db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MfvExlH0aBtj"
      },
      "outputs": [],
      "source": [
        "data_path = '/content/drive/MyDrive/DATA/data.csv'\n",
        "image_dir = '/content/drive/MyDrive/DATA/images/images'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxIOmHvVaiU8"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(data_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xt76MYBtbgJb"
      },
      "outputs": [],
      "source": [
        "image_paths = [os.path.join(image_dir, img_name) for img_name in data['image']]\n",
        "labels = data['class'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1ImEMLwbu6f"
      },
      "outputs": [],
      "source": [
        "# Split into train and test first\n",
        "train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
        "    image_paths, labels, test_size=0.20, random_state=42, stratify=labels\n",
        ")\n",
        "\n",
        "# Further split the train set into train and validation sets\n",
        "train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
        "    train_paths, train_labels, test_size=0.25, random_state=42, stratify=train_labels\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FY_Tu0G0b66x"
      },
      "outputs": [],
      "source": [
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, image_paths, labels, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      image_path = self.image_paths[idx]\n",
        "      image = Image.open(image_path).convert('RGB')\n",
        "      label = self.labels[idx]\n",
        "      if self.transform:\n",
        "        image = self.transform(image)\n",
        "      return image, label\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCVHLBr0b9Gn"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gLA2o6zcBTb"
      },
      "outputs": [],
      "source": [
        "# Create datasets\n",
        "train_dataset = CustomImageDataset(train_paths, train_labels, transform)\n",
        "val_dataset = CustomImageDataset(val_paths, val_labels, transform)\n",
        "test_dataset = CustomImageDataset(test_paths, test_labels, transform)\n",
        "\n",
        "# Create dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zj_DjijJcw6X"
      },
      "outputs": [],
      "source": [
        "model = timm.create_model('vit_small_patch16_224', pretrained=True, num_classes=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTANKjGEcz1q"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQ799Lwoc4a4"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mO5nD-YTc8ZG"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, criterion, optimizer, data_loader, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in data_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = correct / total\n",
        "    return epoch_loss, epoch_acc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNP5_zaJdL2r"
      },
      "outputs": [],
      "source": [
        "def validate_one_epoch(model, criterion, data_loader, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in data_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = correct / total\n",
        "    return epoch_loss, epoch_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qx6dst0pdRLo",
        "outputId": "55d4df0a-36b2-47c0-f102-0b8c9ce40928"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/JpegImagePlugin.py:846: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "Train loss: 0.3643, Train accuracy: 0.8339\n",
            "Val loss: 0.2122, Val accuracy: 0.9235\n",
            "Epoch 2/10\n",
            "Train loss: 0.1049, Train accuracy: 0.9642\n",
            "Val loss: 0.2998, Val accuracy: 0.9104\n",
            "Epoch 3/10\n",
            "Train loss: 0.0636, Train accuracy: 0.9767\n",
            "Val loss: 0.2251, Val accuracy: 0.9283\n",
            "Epoch 4/10\n",
            "Train loss: 0.0234, Train accuracy: 0.9908\n",
            "Val loss: 0.2153, Val accuracy: 0.9446\n",
            "Epoch 5/10\n",
            "Train loss: 0.0126, Train accuracy: 0.9962\n",
            "Val loss: 0.2223, Val accuracy: 0.9381\n",
            "Epoch 6/10\n",
            "Train loss: 0.0071, Train accuracy: 0.9978\n",
            "Val loss: 0.2479, Val accuracy: 0.9430\n",
            "Epoch 7/10\n",
            "Train loss: 0.0036, Train accuracy: 0.9978\n",
            "Val loss: 0.2755, Val accuracy: 0.9430\n",
            "Epoch 8/10\n",
            "Train loss: 0.0032, Train accuracy: 0.9989\n",
            "Val loss: 0.2606, Val accuracy: 0.9430\n",
            "Epoch 9/10\n",
            "Train loss: 0.0030, Train accuracy: 0.9984\n",
            "Val loss: 0.3149, Val accuracy: 0.9349\n",
            "Epoch 10/10\n",
            "Train loss: 0.0023, Train accuracy: 0.9989\n",
            "Val loss: 0.2536, Val accuracy: 0.9430\n"
          ]
        }
      ],
      "source": [
        "# Training and validation functions remain the same\n",
        "\n",
        "num_epochs = 10\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_acc = train_one_epoch(model, criterion, optimizer, train_loader, device)\n",
        "    val_loss, val_acc = validate_one_epoch(model, criterion, val_loader, device)\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "    print(f'Train loss: {train_loss:.4f}, Train accuracy: {train_acc:.4f}')\n",
        "    print(f'Val loss: {val_loss:.4f}, Val accuracy: {val_acc:.4f}')\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), 'best_vit_model2.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('best_vit_model2.pth'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFpcT6J8CzSS",
        "outputId": "01ad1041-a416-4c73-8c00-285038671924"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-b993a9f96f57>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('best_vit_model2.pth'))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the model\n",
        "def test_model(model, data_loader, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in data_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = correct / total\n",
        "    return epoch_loss, epoch_acc"
      ],
      "metadata": {
        "id": "zF0IwF_2L8hL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = test_model(model, test_loader, device)\n",
        "print(f'Test loss: {test_loss:.4f}, Test accuracy: {test_acc:.4f}')"
      ],
      "metadata": {
        "id": "dXb5MZSgRnD0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b73fdb0-e703-4380-ca4a-d1877c2bd2db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.1722, Test accuracy: 0.9301\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx\n",
        "import torch\n",
        "import timm\n",
        "import onnx # Import the onnx module\n",
        "\n",
        "# Instantiate the model\n",
        "model = timm.create_model('vit_small_patch16_224', pretrained=True, num_classes=2)\n",
        "\n",
        "# Load the state dictionary into the model\n",
        "state_dict = torch.load(\"best_vit_model2.pth\")\n",
        "model.load_state_dict(state_dict)\n",
        "\n",
        "model.eval()  # Now you can set the model to evaluation mode\n",
        "\n",
        "# Create dummy input with the appropriate size\n",
        "dummy_input = torch.randn(1, 3, 224, 224)\n",
        "\n",
        "# Export the model\n",
        "torch.onnx.export(model, dummy_input, \"best_vit_model2.onnx\", input_names=['input'], output_names=['class_scores'])\n"
      ],
      "metadata": {
        "id": "yAl8O4dQxI6T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40c62b8b-757b-4fdf-93eb-4aebdfa81c8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (1.17.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-41-7223db6d22c3>:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(\"best_vit_model2.pth\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/__init__.py:2041: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  assert condition, message\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZBN9mTGxF_O1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}